{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import uuid\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Draw Hands\n",
    "<img src=https://i.imgur.com/qpRACer.png />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "i=0\n",
    "with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands: \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # BGR 2 RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Flip on horizontal\n",
    "        image = cv2.flip(image, 1)\n",
    "        \n",
    "        # Set flag\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Detections\n",
    "        results = hands.process(image)\n",
    "        \n",
    "        # Set flag to true\n",
    "        image.flags.writeable = True\n",
    "        \n",
    "        # RGB 2 BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Detections\n",
    "        if i>100:\n",
    "            if results.multi_hand_landmarks is not None:\n",
    "                # show number of detected hand\n",
    "                #print(len(results.multi_hand_landmarks))\n",
    "                print(results.multi_handedness)\n",
    "            i=0\n",
    "        else:\n",
    "            i = i +1\n",
    "        \n",
    "        # Rendering results\n",
    "        if results.multi_hand_landmarks:\n",
    "            for num, hand in enumerate(results.multi_hand_landmarks):\n",
    "                mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS, \n",
    "                                        mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                                        mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2),\n",
    "                                         )\n",
    "            \n",
    "        \n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[x: 0.05860649049282074\n",
       "y: -0.027037518098950386\n",
       "z: 0.03653915598988533\n",
       ", x: 0.02870635874569416\n",
       "y: -0.026414334774017334\n",
       "z: 0.043927185237407684\n",
       ", x: 0.010004724375903606\n",
       "y: -0.01772625371813774\n",
       "z: 0.05776875093579292\n",
       ", x: -0.005950506776571274\n",
       "y: -0.01003408245742321\n",
       "z: 0.07059570401906967\n",
       ", x: -0.027097444981336594\n",
       "y: -0.01261533610522747\n",
       "z: 0.0812157392501831\n",
       ", x: -0.008189732208848\n",
       "y: -0.006711645983159542\n",
       "z: 0.012119894847273827\n",
       ", x: -0.021727677434682846\n",
       "y: 0.001108689233660698\n",
       "z: 0.010405302979052067\n",
       ", x: -0.03757670894265175\n",
       "y: 0.015766039490699768\n",
       "z: 0.021522466093301773\n",
       ", x: -0.04775605723261833\n",
       "y: 0.03534919396042824\n",
       "z: 0.03222312033176422\n",
       ", x: -0.0033880784176290035\n",
       "y: -0.0008861195528879762\n",
       "z: -0.0001528057618997991\n",
       ", x: -0.020936664193868637\n",
       "y: 0.016452960669994354\n",
       "z: -0.004152800887823105\n",
       ", x: -0.03862712159752846\n",
       "y: 0.03950180113315582\n",
       "z: 0.0043049161322414875\n",
       ", x: -0.059981659054756165\n",
       "y: 0.061528559774160385\n",
       "z: 0.023259611800312996\n",
       ", x: 0.005817205645143986\n",
       "y: 0.0061835190281271935\n",
       "z: -0.009674319997429848\n",
       ", x: -0.005919231567531824\n",
       "y: 0.023838678374886513\n",
       "z: -0.01297627855092287\n",
       ", x: -0.023622050881385803\n",
       "y: 0.049105044454336166\n",
       "z: -0.0040849195793271065\n",
       ", x: -0.04149934649467468\n",
       "y: 0.07014541327953339\n",
       "z: 0.013371500186622143\n",
       ", x: 0.019872356206178665\n",
       "y: 0.012917418032884598\n",
       "z: -0.006300285924226046\n",
       ", x: 0.01006887387484312\n",
       "y: 0.027436407282948494\n",
       "z: -0.008128838613629341\n",
       ", x: -0.004117565229535103\n",
       "y: 0.05161566287279129\n",
       "z: -0.0038124171551316977\n",
       ", x: -0.01624523289501667\n",
       "y: 0.06964392960071564\n",
       "z: 0.009284276515245438\n",
       "]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.multi_hand_world_landmarks[0].landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[index: 1\n",
       "score: 0.9958252906799316\n",
       "label: \"Right\"\n",
       "]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.multi_handedness[0].classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints = []\n",
    "for data_point in results.multi_hand_world_landmarks[0].landmark:\n",
    "    keypoints.append({\n",
    "        'X': data_point.x,\n",
    "        'Y': data_point.y,\n",
    "        'Z': data_point.z,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing.DrawingSpec??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Output Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('Output Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands: \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # BGR 2 RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Flip on horizontal\n",
    "        image = cv2.flip(image, 1)\n",
    "        \n",
    "        # Set flag\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Detections\n",
    "        results = hands.process(image)\n",
    "        \n",
    "        # Set flag to true\n",
    "        image.flags.writeable = True\n",
    "        \n",
    "        # RGB 2 BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Detections\n",
    "        print(results)\n",
    "        \n",
    "        # Rendering results\n",
    "        if results.multi_hand_landmarks:\n",
    "            for num, hand in enumerate(results.multi_hand_landmarks):\n",
    "                mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS, \n",
    "                                        mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                                        mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2),\n",
    "                                         )\n",
    "            \n",
    "        # Save our image    \n",
    "        cv2.imwrite(os.path.join('Output Images', '{}.jpg'.format(uuid.uuid1())), image)\n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
